\documentclass{beamer}
%\usetheme{Warsaw}
%\usetheme{split}
%\usetheme{Amsterdam}
\usetheme{Madrid}
\useoutertheme{miniframes}
\setbeamercovered{invisible}
\setbeamertemplate{navigation symbols}{}
%
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
% \usepackage{beamerthemesplit}
%
\graphicspath{{../images/}}
%
\title{SSD-based Energy Efficient Cloud Storage}
\author{Salma Rodriguez}
\institute [FIU]{
	Florida International University \\
	%\medskip
{\emph{srodr063@fiu.edu}}}
\date{\today}
%
\begin{document}
%
\section{Introduction}
%
\begin{frame}
	\titlepage
\end{frame}
%
\begin{frame}
	\frametitle{Motivation}
	\begin{block}
		{Solid State Technology}
		High capacity EEPROM devices have been shown to
		reduce power consumption when used
		as local cache for hard disk drives \cite{key2,key3}.
	\end{block}
	\vspace{7pt}
	\begin{block}
		{Distributed SSD Caching}
		With a distributed caching solution, we hope to increase
		the working set in flash memory and keep server disks spun down.
	\end{block}
	\vspace{7pt}
	\begin{block}
		{Properties to Explore}
		We explore the properties of dynamic spin down of storage
		server disks and replication of cold pages.
	\end{block}
\end{frame}
%
\begin{frame}
	\frametitle{Linux Device Mapper}
	\begin{tabular}{m{0.465\linewidth}m{0.465\linewidth}}
		%\hline
		\begin{itemize}
			\item device mapper facilitates mapping between block devices
			\item only pseudo device is visible to applications
			\item kernel module uses device mapper to map bios sent to pseudo
				device onto real devices
			\item devices may not necessarily be locally attached
		\end{itemize} &
		\begin{figure}
			%\caption{Device Mapper Layout}
			\centering \includegraphics[scale=.23]{DM.png}
			\label{fig:dm}
		\end{figure} \\
		%\hline
	\end{tabular}
\end{frame}
\begin{frame}
	\frametitle{Device Mapper Cache}
	\begin{itemize}
		\item client machines communicate through iSCSI or AoE network
		\item DM Cache takes advantage of spatial and temporal locality
			by storing popular data in a local cache.
	\end{itemize}
	\begin{figure}
		\centering \includegraphics[scale=.30]{DMC.jpg}
		\label{fig:dmc}
	\end{figure}
\end{frame}
%
\section{Dynamic Disk Spin}
%
\begin{frame}
	\frametitle{Dynamic Spin: Design}
	\begin{figure}
		%\caption{Spinning state is controlled dynamically}
		Figure 1: Spinning state is controlled dynamically
		\centering \includegraphics[scale=.43]{drawing.png}
		\label{fig:struct}
	\end{figure}
\end{frame}
%
\algrenewcommand\algorithmicrequire{\textbf{Precondition:}}
\begin{frame}
	\frametitle{Dynamic Spin: Implementation}
	\bf Algorithm 1 \rm Spinning the disk up or down dynamically \\
	\begin{algorithmic}[1]
		\Require{storage server disk is spinning}
		\Procedure{Spin Up or Down}{}
		\While {true}
		\If{disk is spinning}
		\State $k\gets$ current time in seconds
		\State $c\gets$ time since last cache miss
		\If{$c$ + $20 \leq k$}
		\State spin down the disk and change state to not spinning
		\EndIf
		\Else \Comment{disk is not spinning}
		\If{DM Cache is blocking on a cache miss}
		\State spin up the disk and change state to spinning
		\State unblock DM Cache
		\EndIf
		\EndIf
		\EndWhile
		\EndProcedure
	\end{algorithmic}
\end{frame}
%
\section{Future Work}
\begin{frame}
	\frametitle{Replication}
	\begin{block}{Basic Idea}
		Save power by replicating unused clean data to neighboring caches
		instead of evicting from the cache.
	\end{block}
	\begin{block}{Assumption}
		Not all clients will have their cache
		full to capacity.
	\end{block}
	\begin{block}{Challenges}
		\begin{itemize}
			\item Choose efficient cache replacement policy to
				evict pages that are less popular to other caches.
			\item Cache cooperatively by handling nodes as they dynamically
				join and exit the network of peer caches.
		\end{itemize}
	\end{block}
\end{frame}
\begin{frame}
	\frametitle{Consistent Hashing}
	Idea: may save power by replicating data with as little disruption
	as possible when nodes join and exit the network. \\
	\begin{theorem}
		For any set of N nodes and K keys, with high probability:
		\begin{enumerate}
			\item Each node is responsible for at most (1 + $\epsilon$)K/N keys.
			\item When an (N + 1)st node joins or leaves the network,
			responsibility for O(K/N) keys changes to the joining node, or from
			the leaving node.
		\end{enumerate}
	\end{theorem}
	Here $\epsilon$ may vary but has an upper bound of \textit{O(log N)} \cite{key1}.
	\begin{block}
		{Challenge}
		Dynamically maintain mapping of block addresses to network nodes as new
		data is replicated to neighboring client caches.
	\end{block}
\end{frame}
%
%section{Verbatim}
%begin{frame}[fragile]
%frametitle{Verbatim}
%begin{example}[Putting Verbatim]
%begin{verbatim}
%begin{frame}
%frametitle{Outline}
%begin{block}
%Why Beamer?}
%
%end{block}
%
%end{frame}\end{verbatim}
%end{example}
%end{frame}
%
%begin{frame}[fragile]
%
%xample of the \verb|\cite| command to give a reference:
%xample of citation using \cite{key1} follows on.
%end{frame}
%
\section{References}
\begin{frame}
	\frametitle{References}
	\footnotesize {
		\begin{thebibliography}{98}
			\bibitem[1]{key1} I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, and H. Balakrishnan.
			Chord: A Scalable Peer-to-peer Lookup Service for Internet Applications.
			\emph{Special Interest Group on Data Communication (SIGCOMM '01)},
			San Diego, California, Aug. 2001.
			\bibitem[2]{key2} J.D. Garcia, J. Carretero, and F. Garcia.
			Saving power in flash and disk hybrid storage system.
			\emph{Modeling, Analysis \& Simulation of Computer and Telecommunication Systems
				(MASCOTS 2009)}, London, U.K., Sep. 2009.
			\bibitem[3]{key3} T. Bisson and S. A. Brandt.
			Reducing Energy Consumption with a Non-Volatile Storage Cache.
			\emph{International Workshop on Software Support for Portable Storage (IWSSPS)
				held in conjunction with the IEEE Real-Time and Embedded Systems and Applications
				Symposium (RTAS 2005)}, Mar. 2005
		\end{thebibliography}
	}
\end{frame}
%
\end{document}
